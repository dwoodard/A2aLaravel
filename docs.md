Laravel A2A Package Implementation Plan
Eloquent Models and Data Structure
Task Model: Represents each A2A task with full lifecycle tracking. Key fields include a unique id (string UUID generated by the client per A2A spec
google.github.io
), optional session_id (to group related tasks), current state (enum: submitted, working, input-required, completed, canceled, failed
google.github.io
), and timestamps. It also stores metadata (JSON for custom info or tracing) and references to related records.
Maintains relations to Message and Artifact models. A task has many messages (conversation history) and may have multiple artifacts (outputs). The model’s history and artifacts fields are serialized in JSON responses per A2A spec (showing recent messages if requested
google.github.io
 and output artifacts).
Task States: The model enforces allowed states (e.g., submitted upon creation, working when execution starts, input-required if awaiting more input, completed on success, failed on error, canceled if aborted
google.github.io
). State transitions are handled through a dedicated service to ensure consistency (see TaskManager below).
Message Model: Captures each message exchanged in a task’s dialogue. Fields include task_id, role (either "user" for client messages or "agent" for agent responses
medium.com
), and content. The content can be stored as structured JSON parts (to support multi-part messages like text + file). For simplicity, the model may have a content JSON column containing an array of parts (text chunks, file references, or structured data). Each message also has timestamps and potentially an index or sequence number. The latest agent message can serve as the task’s status message (e.g., an error detail or prompt for input, corresponding to TaskStatus.message
google.github.io
).
Message Parts: If needed, define sub-types for message content (e.g., a MessagePart model for text vs. file parts), but a JSON structure is sufficient. This allows the agent to handle rich content (images, JSON payloads) as per A2A’s design for multi-modal messages
medium.com
.
Artifact Model: Represents outputs or files produced by the agent for a task (tangible results). Fields include task_id, name or type, and data or reference (e.g., file path or JSON content). Artifacts might be stored as files on disk or as database records containing serialized data. The model also tracks indexing and metadata (to support chunked or multiple artifacts per task, aligning with A2A artifact structures
google.github.io
). All artifacts belonging to a task are accessible via task->artifacts.
PushNotificationConfig Model (optional): Stores push notification settings for tasks if push is enabled. Fields could include task_id, target_url (webhook URL for notifications), token (secret token for verification), and auth (serialized auth credentials to use when calling the webhook). This corresponds to the A2A push config (with an HTTPS URL and optional token) that a client might set
google.github.io
. In many cases, these can also be stored in the Task’s metadata, but a dedicated model or table helps manage secure credentials separately.
Relationships & Indexing: Define Eloquent relationships: Task hasMany Messages, Task hasMany Artifacts, Task hasOne PushNotificationConfig. Use eager loading for task history and artifacts when returning a Task response to include history and artifacts arrays
google.github.io
. Ensure id fields are indexed (for quick lookup on tasks by ID and for foreign keys on messages/artifacts). The Task id is a primary key or uniquely indexed string (to directly use client-provided task IDs).
Routes and API Endpoints
Agent Discovery Endpoint (GET /.well-known/agent.json): The package registers a route to serve the Agent Card JSON at the well-known URI as recommended
google.github.io
. This discovery document advertises the agent’s identity and how to interact with it. It includes:
Agent Metadata: Name, description, version, provider info, and documentation URL (all configurable via a2a.php). For example, name, description, and version come from config to identify the agent.
Service URL: The base URL for JSON-RPC API calls (likely the route for tasks, e.g., <https://your-app.com/a2a>), included as url in the card
google.github.io
. The package will populate this automatically based on configuration or route registration (e.g., if the API is mounted at /a2a).
Capabilities: Indicates if streaming and push notifications are supported by this agent. These flags (capabilities.streaming and capabilities.pushNotifications) are set to true if our package has those features enabled
google.github.io
. For example, if SSE streaming endpoints are active, streaming: true will be advertised; if webhook push is implemented, pushNotifications: true is advertised.
Authentication Requirements: Describes any auth scheme needed to call the agent. If the config a2a.php specifies an API key or OAuth, the Agent Card will list the scheme (e.g., "ApiKey" or "OAuth2") under authentication.schemes and may provide non-secret info like auth endpoints or header names
google.github.io
. By default, the package can allow open access for development (no auth required), but in production this should be configured (the card can be protected or include scheme hints as needed). The .well-known route itself can be left public or behind auth based on the user’s app requirements (the spec notes that sensitive info in Agent Cards should be protected
google.github.io
).
Skills List: An array of skills offered by the agent, pulled from the Skill registry (see Skill Discovery). Each skill entry includes its id, human-readable name, description, tags, examples, and I/O content types
google.github.io
google.github.io
. This is automatically generated by the package by iterating over all registered skills and serializing their metadata into the Agent Card response.
JSON-RPC Endpoint (POST /a2a or similar): A single POST endpoint handles all JSON-RPC 2.0 requests from other agents (the exact path is configurable, default /a2a matching the Agent Card’s URL path). This is the core entry point for tasks and follows JSON-RPC standards (accepting a JSON body and returning a JSON response). The controller for this route will parse the incoming JSON and dispatch it to the appropriate method handler based on method name:
tasks/send: Initiates a new task or continues an existing one. The controller validates the JSON-RPC request (must include "jsonrpc": "2.0", a method, an id, and params) and specifically checks that params.id (task ID) and a message are provided
google.github.io
. On valid request, it invokes the TaskService (or TaskManager) to handle task creation/execution (see lifecycle below). It then returns a JSON-RPC Response with a Task object as result on success
google.github.io
. If the task is long-running, the result may indicate a non-terminal state (e.g., state “working”) and the client can poll or wait for updates. Errors (invalid input, unknown skill, etc.) are returned with appropriate JSON-RPC error codes.
tasks/sendSubscribe: Initiates a task and opens a Server-Sent Events stream for real-time updates (requires that capabilities.streaming is true on our side). When the controller sees a tasks/sendSubscribe method, it will upgrade the HTTP response to an SSE stream (Content-Type text/event-stream)
google.github.io
. The request params are the same as tasks/send, and initial validation/handling is similar. The difference is that instead of returning a JSON payload immediately, the server flushes an SSE stream of events. The controller will likely call the TaskService to start the task (potentially sending an initial partial Task in submitted/working state), then keep the connection open. As state changes or artifacts are produced, events are written to the stream in JSON format (each SSE data: contains a JSON-RPC style response with an update event
google.github.io
). When the task reaches a terminal state (completed/failed/etc.), a final event with final: true (as part of the TaskStatusUpdateEvent) is sent and the stream is closed
google.github.io
. The route might be implemented via a streaming response or a long-running controller action that uses PHP output buffering flush; we will ensure Laravel is set to allow SSE (disabling view buffering for that route, etc.).
tasks/get: Allows polling for task status. This method expects a task ID in params (TaskQueryParams) and returns the current Task object (including status, and optionally recent history/artifacts if historyLength was specified)
google.github.io
. The controller will look up the Task model by ID and return its serialized representation. This is used by clients who did a tasks/send without SSE or push to check on progress or fetch final results.
tasks/cancel: Cancels an ongoing task. On receiving this, the controller calls the TaskManager to mark the task as canceled and attempts to abort execution (e.g., by signaling a running job). It returns either a success (perhaps the updated Task or a bool) or an error if the task isn’t found or already terminal. Cancelled tasks trigger events just like other state changes.
Push Notification RPC (tasks/pushNotification/*): If push notifications are supported, the agent must handle tasks/pushNotification/set and tasks/pushNotification/get. Our package’s controller will implement:
tasks/pushNotification/set: Configures where the server agent (us) should send updates for a given task
google.github.io
. The client includes a TaskPushNotificationConfig (with webhook URL, token, etc.) in params. We validate and save this (create or update a PushNotificationConfig tied to the Task). On success, respond with the stored config (masking any sensitive credentials)
google.github.io
. If our agent did not enable push in capabilities, respond with an error (OperationNotSupported).
tasks/pushNotification/get: Returns the current push config for a task (if any)
google.github.io
. We fetch from DB (PushNotificationConfig model) and return it. If none set or not supported, return appropriate error.
Both of these allow other agents (clients) to programmatically set up webhooks. Note: The actual sending of push notifications is done by our side when task events occur (discussed under Notifications).
tasks/resubscribe: Handles a client re-connecting to an SSE stream for an ongoing task
google.github.io
. If a client loses an SSE connection, it can call tasks/resubscribe (likely as an SSE request again). The controller will verify the task is still active and then respond with a new SSE stream continuing updates. Implementation-wise, this can reuse the logic of sendSubscribe but without re-triggering the initial execution (just streaming remaining/new events). If the task is already done or streaming not available, return an error.
Authentication & Middleware: If the agent requires authentication (as advertised in the Agent Card), the package can provide middleware to enforce it on the JSON-RPC route. For example, an ApiKeyAuth middleware can check for a header or token, or an OAuth middleware can integrate with Laravel Passport. These would be configured via a2a.php (e.g., specify a guard or token to require). By default, no auth is required (for easy local testing), but it’s configurable to meet enterprise requirements (e.g., enforcing mTLS or an API token in production).
File/Artifact Endpoints (Optional): If the agent needs to allow downloading artifacts (like generated files), the package might include a route to fetch artifact contents. For instance, if an Artifact is large or binary, instead of including raw data in JSON, the Artifact in the Task could contain a URL pointing to a download route. A route like GET /a2a/tasks/{taskId}/artifacts/{artifactId} could serve the file. The package can protect these routes (require an auth token or link) and ensure they only serve files belonging to the requesting party. This isn’t explicitly mandated by A2A, but it aligns with the file exchange example in the spec (where artifacts can be downloaded separately)
google.github.io
.
Internal Endpoints for UI (Future): Though a UI isn’t bundled, we plan routes that make it easy to plug one in. For example, GET /a2a/tasks (authenticated for internal use) could list recent tasks and their statuses, or GET /a2a/tasks/{id} returns full task details. These could reuse the JSON-RPC tasks/get logic but present data in a UI-friendly format. By structuring controllers cleanly, adding a web dashboard later would be straightforward (e.g., a Vue/React frontend could poll or subscribe to the same events).
Core Services and Controllers
AgentService (A2A Service): This service class acts as a facade for high-level A2A operations. It coordinates both server-side and client-side functionality. Key responsibilities:
Registering the agent’s metadata and skills (from config) and generating the Agent Card data structure for the discovery endpoint. It may have a method like getAgentCard() that compiles the config and skill info into the proper JSON structure (Agent name, URL, capabilities, etc.)
google.github.io
.
Handling inbound JSON-RPC requests: the AgentService will map JSON-RPC methods to internal handlers. For example, on a tasks/send request, it calls AgentService->handleSend($params) which uses TaskManager and SkillRegistry to execute the task. This keeps the controller thin and logic in a testable service. Each handler (handleSend, handleGet, handleCancel, etc.) will perform validation and business logic, then return a result or throw an exception that the controller translates to a JSON-RPC error.
Initiating outbound JSON-RPC calls (client role): AgentService provides methods to act as an A2A client. For instance, AgentService->sendTaskToAgent($agentUrl, $taskId, $message, $options) will formulate a JSON-RPC request (using the given task ID and message) and send it via HTTP to the remote agent’s url. Under the hood it uses the RPC Client (described below). This allows our Laravel app to delegate tasks to other agents easily. The service can also handle retrieving remote Agent Cards (discoverAgent($url) to GET agent.json and parse it).
TaskManager: A dedicated service (or set of methods in AgentService) to manage task lifecycle and persistence. This handles creation of Task records and any state transitions:
Create/Start Task: When a new task request arrives, TaskManager creates a Task model (state = submitted initially). It attaches the initial user Message (saves a Message model with role "user"). Then, it dispatches execution via a Skill (or queues it), and immediately updates state to working.
State Updates: Provides methods like markWorking(Task), markInputRequired(Task, promptMessage), markCompleted(Task, resultMessage, artifacts) and markFailed(Task, errorMessage). These update the Task’s status field and timestamp, append any new Message or Artifact records, and fire the corresponding Laravel Events for the transition. By centralizing this, we ensure every state change triggers consistent side effects (events, notifications).
Task Lookup: Also provides helper to fetch tasks by ID and include related data (for tasks/get and internal uses).
Cancellation: Implements logic to cancel tasks. E.g., if a task has an associated queued job, TaskManager can dispatch a cancel signal (perhaps via a Cache flag or an event that the running job checks). If the task is currently working, it marks it canceled and fires events. It handles edge cases (no-op if already finished).
SkillRegistry: Manages the registration and lookup of agent Skills. At package boot, it will load all configured skills (from a2a.php or auto-discovered classes):
Could be implemented as a simple list or map of skill id to an object/closure. For class-based skills, the registry may instantiate each skill class (or use singletons) and store their metadata (id, name, description, etc.) plus a callable for execution. For closures defined in config, it wraps them into a skill entry with given metadata.
Provides methods like getSkillById($id) to retrieve a skill by its identifier, or allSkills() to list all for building the Agent Card. It also might support skill discovery by name/tags if needed.
Auto-discovery: The package can auto-discover skills by scanning a directory or using Laravel’s package discovery. For example, we might conventionally place skill classes in App\A2A\Skills\ and use reflection to find classes implementing a SkillInterface. The SkillRegistry can scan these at runtime or on package install (potentially with an Artisan command to cache the list). Auto-discovery removes the need to manually list every skill in config, though we will also allow explicit registration via config for flexibility.
Skill Definition: We define a SkillInterface or abstract base (e.g., AgentSkill) that skill classes must implement. This interface includes methods or properties for the required metadata: id(): string; name(): string; description(): string; inputSchema(): array; outputSchema(): array; execute(Task $task, Message $inputMessage): mixed. A skill class can also declare an $signature or static $metadata property for easier configuration. The package will use these to populate the Agent Card’s skills array
google.github.io
.
Closure Skills: In config, users can register a skill with an identifier and closure. For instance, 'skills' => [ 'weather-lookup' => [ 'name' => 'Weather Lookup', 'description' => 'Provides weather info', 'handler' => function($task, $message) { ... } ] ]. The registry will wrap this into a Skill object internally. This lowers the barrier for simple skills that don’t need a full class.
Skill Execution/Dispatcher: When a task is started, the TaskManager will identify which skill to invoke. This could be done by examining the incoming message or an explicit field. For direct mapping, we might allow the client to specify the skill by ID in the Task’s metadata or as a structured message (the spec allows using skill IDs if supported
google.github.io
). If a skill ID is present (e.g., in Message.content or params.metadata), we lookup that skill. Otherwise, a default skill (or a routing logic) could decide which skill fits the request (for instance, a simple agent might only have one primary skill). The SkillDispatcher (which could be part of TaskManager or a separate class) then calls the skill’s execute method or closure.
Queued vs Sync Execution: To avoid blocking HTTP requests for long tasks, the package integrates with Laravel’s queue. By default, tasks/send will operate synchronously up to a configurable threshold (quick tasks can return immediately), but anything expected to take long will be offloaded to a job. For tasks/sendSubscribe, we definitely dispatch a background job for the actual processing, so the SSE stream can asynchronously receive events. The Task model might have a flag or status to indicate if a job is pending/running. The SkillDispatcher can either run the skill immediately (for quick response) or push it to a queue (Dispatchable job) that knows how to report progress. We will use Laravel’s queued jobs with event broadcasting (the job can fire Task events as it progresses, which are picked up by SSE or push).
Skill Output Handling: When a skill’s execution finishes (whether in the same request or in a job), it should report the results back. If the skill returns a value or throws an exception, the TaskManager will capture that: a return value might be packaged into a final Message or Artifact, whereas an exception triggers a failed state. We’ll formalize this by expecting skill handlers to either return a result (which could be text, data, or file path) or throw a custom InputRequiredException if they need more input (to signal input-required state), or other exceptions for errors (triggering failed). The TaskManager catches these and updates the task accordingly (e.g., on InputRequiredException, it stores the provided message prompt from the agent and sets state input-required).
Multi-turn Support: If a task goes into input-required, the agent will not complete it until further input arrives. The client is expected to call tasks/send again with the same task ID and a new user message. Our controller (and TaskManager) will detect that the Task exists and is awaiting input, then resume execution. This could involve calling the same skill’s execution method again or a different handler for continuation. The Message history stored in the DB is used to provide context to the skill if needed. Skills could be written to handle incremental inputs (for instance, a skill might maintain state in the Task’s metadata between calls). This mechanism allows interactive workflows within a task.
RPC Client & HTTP Integration: The package uses Laravel’s HTTP client (e.g., the Http facade which wraps Guzzle) for outbound requests to other agents. We provide an A2AClient class or methods in AgentService that perform these calls:
Formulate JSON-RPC requests given a target agent (its base URL from the Agent Card), method, and params. This includes generating a unique JSON-RPC id (if not provided) and ensuring "jsonrpc": "2.0" is set.
If the target agent requires authentication as per its Agent Card, the client will attach the necessary headers or tokens. For example, if the agent’s authentication.schemes includes "Bearer", our config may hold a token to use; if "ApiKey", the config can specify which header and value to send. The A2AClient will use this info (possibly prompting the developer to configure credentials for known agents).
Execute the HTTP POST to the agent’s URL and parse the JSON response. If it’s a normal tasks/send, we get a JSON result (Task object) or an error. If it’s tasks/sendSubscribe (streaming), the client should handle an SSE response. We will support streaming by either providing a callback interface or a separate SSE client utility. For example, A2AClient might have subscribeTask($agentUrl, $params, $onEventCallback) that opens an SSE stream (using an underlying HTTP client or even a simple EventSource in a Node process if applicable) and invokes the callback for each incoming event. In PHP, true SSE client handling is tricky; so initially, we might handle streaming by falling back to push notifications (i.e., instead of maintaining an SSE client, we register our own webhook and call tasks/send with push config so the remote agent pushes updates to us). Nonetheless, the package design accommodates either mode.
The A2AClient can also abstract polling: e.g., a method waitForCompletion($agentUrl, $taskId) that periodically calls tasks/get until a terminal state is reached, for simpler synchronous usage when SSE/push aren’t used. This helps in testing or simple scripts.
Integration with Task Model: If our agent is delegating a sub-task to another agent, we might represent that with a local Task record as well (to track the outbound task). For example, if Agent A calls Agent B via A2A, Agent A can create a Task entry for the sub-task and mark it as externally executing. When Agent B’s response or push update comes in, we update that Task. This design means our Task model can represent both tasks we perform and tasks we have requested remotely. A field like initiator_role (client or server) or a boolean can distinguish them. By modeling outbound tasks, a developer can treat all tasks uniformly in the UI or logs. The A2AClient would then create and update these Task records under the hood if configured to do so.
Task Lifecycle Workflow (End-to-End Example)
This section ties together models, routes, and services to illustrate the full lifecycle of a task, from request to completion, including state transitions and notifications:
Receiving a Task Request: Another agent (client) sends a JSON-RPC request to our /a2a endpoint with method tasks/send (or tasks/sendSubscribe). For example, a POST comes in with {"jsonrpc":"2.0","id":"1234","method":"tasks/send","params":{...}}. The Laravel route maps this to our A2A Controller (registered by the package).
The Controller authenticates the request if required (e.g., checks an API token header if our agent demands it). Then it parses the JSON body. A validation layer ensures required fields are present (task id, message, etc.), following A2A’s JSON schema. If invalid, it returns a JSON-RPC error (-32602 Invalid params, etc.) without touching the DB.
On valid input, the controller delegates to AgentService->handleSend($params) and passes along the parsed TaskSendParams.
Task Creation: The AgentService/TaskManager creates a new Task model instance. It uses the provided id (the spec requires the client-generated ID be used as the task identifier
google.github.io
, ensuring uniqueness). The initial state is set to submitted
google.github.io
 and a timestamp recorded. It also stores session_id if provided (to group tasks). This is saved to the DB.
The incoming message (user query) is saved as a Message record (role "user"). If a historyLength was requested, the TaskManager can fetch prior messages – but since this is a new task, history is empty (or if continuing an existing task, we’d load that task and attach the new message to its history instead).
Skill Dispatch: The TaskManager/SkillDispatcher determines which skill should handle this message. Suppose the client’s message was “Convert 100 USD to EUR” and our agent has a skill with id = "currency-converter". The client might have included that skill ID in metadata or we might match the message to the skill by keyword. For this example, assume it finds the "currency-converter" skill.
The Task’s state is moved to working as we begin processing. We update the Task record (state = working) and fire a TaskStatusUpdated event (state changed to working). At this point, if the request was a normal tasks/send (no SSE), we could choose to return early with the Task status. However, typically we attempt to produce a final result within the same request if it’s quick. We will handle both synchronous and async flows:
Synchronous Fast Execution: If the skill’s execution is fast (sub-second), the package can execute it inline. The Skill’s execute() method is called with the task context. Say our currency converter skill immediately returns {"result": "€90.50"}. The TaskManager records this output: perhaps as an Artifact or as a final Message (role "agent") containing the result. It then updates state to completed, and sets the TaskStatus.message to that final message. The Task’s artifacts could also include a small data artifact (like a JSON with the numeric result). We fire a TaskCompleted event. Finally, the AgentService returns the Task object (now completed) as the JSON-RPC Response. The controller wraps it in {"jsonrpc":"2.0","id":"1234","result":{...Task...}} and sends it back to the caller. This completes the cycle in one go.
Asynchronous Execution: For longer tasks, or if the request is tasks/sendSubscribe (or if our design always defers to background jobs), we will not block the HTTP request until completion. Instead, after marking state working and firing the event, we dispatch a Job to handle the skill execution. This job (e.g., ExecuteTaskJob) knows the Task ID and maybe the skill ID. It will perform the skill logic in the background. Meanwhile, what do we return to the client?
For a plain tasks/send request, we can return the Task object as it currently stands: state “working” (or “submitted” if we want to indicate queued), and perhaps no artifacts yet. This tells the client the task is in progress
google.github.io
. The client can then poll or wait for push updates. We include the task id in the response so the client can use tasks/get later.
For a tasks/sendSubscribe request, we do not return a JSON body. Instead, we have kept the SSE connection open. We immediately send an SSE event containing a TaskStatusUpdateEvent with state “working” (this acts as an acknowledgement that the task started). The HTTP response remains open to stream further events. The client, having requested streaming, will be listening for these SSE events.
Job Processing (async path): The queued job picks up the task. It loads the Task from the DB, then invokes the corresponding skill’s execution. For example, if the task is a complex report generation, the skill might stream intermediate progress. Within the job, the skill can use the TaskManager to report progress: e.g., call TaskManager->updateStatus($task, 'working', $progressMessage) periodically. Each call triggers a TaskStatusUpdated event. Our SSE connection handler (on the server) will catch those and push SSE events to the client in real-time (see Notifications section). If push notifications were set, a listener will also send those updates to the client’s webhook. The job continues until the skill signals completion or failure.
Input Required scenario: Suppose during execution, the skill realizes it needs more data (maybe the user asked to generate an image but no size was provided). The skill can throw an InputRequiredException with a message like “Please provide the desired image resolution.” The Task job catches this and uses TaskManager to set state to input-required. We save the agent’s prompt as a Message (role "agent"), update Task.status.message to that prompt, and fire TaskStatusUpdated. For SSE, an event is sent with the new status; for push, a webhook is sent as well. The job then exits without marking completed (the task remains open awaiting input). The client agent receives the prompt and can now decide to supply additional info by calling tasks/send again with the same task ID and a new message. Our controller will route that to the existing Task: instead of creating a new one, TaskManager finds the task by ID, appends the new user message, and resumes the job (perhaps dispatching a fresh job or directly calling the skill again, now with the additional input). This loop continues until the skill has what it needs to complete or decides to fail/cancel.
Task Completion: When the skill finishes successfully, the job collects the result. The result could be plain text, a complex JSON, or even binary data. The TaskManager will finalize the Task: state -> completed, attach any output. Output handling might involve: if the result is a simple text or answer, we create a final Message (role "agent") containing it and also set TaskStatus.message to it. If the result includes files or structured data, we create Artifact records (and possibly include a summary or link in the status message). The history will contain the entire dialogue (user messages and agent responses) if needed. We mark completion time (could use Task updated_at as completion timestamp). Then fire a TaskCompleted event.
Returning Response to Client:
In the SSE case, as soon as the job marked the task completed and fired the event, our SSE stream handler sends out that final event (with TaskStatusUpdateEvent including state "completed" and possibly result data). It then closes the connection from our side. The client’s SSE listener sees event: message (or just default) with data containing the JSON result and final:true, indicating the task is done
google.github.io
. No further action is needed; the client has received the result in real-time.
In the non-streaming case where we returned an in-progress Task earlier, the final result will reach the client either via push notification (if they set one up) or by the client polling tasks/get. If push was configured initially (TaskSendParams.pushNotification provided
google.github.io
), our job’s completion event triggers the push mechanism (see below) to POST the final Task to the client’s webhook. If no push, the client can call tasks/get at intervals to obtain the Task object, which will now show state completed and include the outputs. Our implementation of tasks/get simply reads from the database; since the job updated the Task, it will return the fresh data.
Error Handling: If the skill code throws a general exception or something goes wrong (e.g., an API call fails inside the skill), the job catches it and marks the Task as failed. We update Task.status.state = failed and TaskStatus.message with an error message (which could be a sanitized exception message or a generic “Internal error”). Fire TaskFailed event. SSE/push will transmit this status. The JSON-RPC spec expects the initial call to return an error in some cases; however, since we’re doing async, we likely already returned a success ack. In an SSE flow, we can send an SSE event with an error field just before closing
google.github.io
. In a pure sync call scenario, if the skill fails immediately, we would instead return a JSON-RPC error response (with code -32000 or a custom A2A error code) instead of a Task result. Our implementation will differentiate between failures caught after sending a partial response (handled via events) vs failures that occur before sending any response. We will map error types to A2A-specific error codes where appropriate (e.g., OperationNotSupported, TaskNotFound, etc., as defined in the spec
google.github.io
google.github.io
).
Initiating an Outbound Task: Our Laravel app (using the package) can also act as a client to request tasks from other agents. Here’s the lifecycle for outbound requests:
A developer (or an automated workflow) calls our package’s client API, e.g., AgentService::sendTaskToAgent($agentUrl, $taskId, $message, $options). Under the hood, we fetch or have cached the target’s Agent Card (if not, use a2a:discover command or an AgentDirectory to get it). We then prepare a JSON-RPC payload for tasks/send or tasks/sendSubscribe depending on needs. The taskId could be generated here (we typically generate a UUID for the new task as client)
google.github.io
.
If using tasks/sendSubscribe and streaming, the AgentService might choose to handle updates via SSE client. But an easier path is to use push: the options can include pushNotification config such that we tell the remote agent to push updates to our webhook. Our package can expose an internal webhook endpoint (maybe POST /a2a/webhook) that simply receives push updates (which would be JSON-RPC calls of type tasks/pushNotification/get from the remote agent). In the push config we provide to remote, we include a token and perhaps an authentication scheme so the remote agent can call us securely
google.github.io
. When the remote agent calls our webhook with updates, our controller will interpret that (likely as just another JSON-RPC request or a raw POST with Task data) and update the corresponding Task record on our side, then fire events for our UI. This effectively bridges the remote agent’s push into our local event loop.
If not using push, and SSE is desired, the AgentService will spawn a background process or thread to listen to SSE. This could be done with something like a ReactPHP event loop or simply a long-lived PHP process if the environment allows. Alternatively, without fancy async, we fall back to polling the remote with tasks/get periodically.
In all cases, we likely create a Task entry locally representing the outbound task (with our generated ID, state submitted). This allows our local app to treat it uniformly (the user could see it in a tasks list as “waiting on external agent”). As responses come in (via push events or poll results), we update that Task’s state and data accordingly. When the remote signals completion, we mark it completed on our side too. Essentially, our package will manage a mirror of the remote task. This is optional (the developer may simply await the RPC result without creating a local Task), but it is useful for integration and observation.
Finally, the result from the remote agent is returned by AgentService to the caller (if it was a direct call). If the call was made via CLI or an automated job, the result might be handled there instead. The important part is our client logic will honor the remote agent’s capabilities (e.g., if remote doesn’t support push, we do polling or blocking request; if remote supports streaming and we requested it, we handle SSE or push accordingly).
Throughout these flows, our design emphasizes that tasks are first-class entities in the Laravel app, and all transitions are captured and can trigger further actions (notifications, UI updates, etc.). Next, we detail those notification mechanisms.
Real-Time Notifications and Event Broadcasting
A cornerstone of this package is notifying interested parties (other agents or UIs) about task progress. We use Laravel’s event system to broadcast changes and integrate SSE and push seamlessly:
Domain Events for Tasks: We define events for key task lifecycle moments, for example: TaskSubmitted, TaskStarted (or combined with submitted), TaskProgressUpdated, TaskInputRequired, TaskCompleted, TaskFailed, TaskCanceled. We also have events for artifact creation like TaskArtifactAdded if needed. Each event carries the Task model (or a lightweight DTO with task ID, new state, and any relevant message/artifact data). The TaskManager will fire these events whenever a state transition or notable update occurs.
The events implement Laravel’s ShouldBroadcast interface if we want them on websockets, or we emit separate broadcast events. We can also broadcast on specific channels (e.g., tasks.{id} for per-task updates, and/or tasks for general monitoring). This allows a front-end to subscribe via Laravel Echo to live updates.
We ensure these events are queued (by marking them ShouldQueue or using broadcast queue) so that broadcasting (especially potentially slow push webhooks) does not block the main thread. The package’s default config can specify an events_queue for A2A events.
Server-Sent Events (Agent-to-Agent Streaming): For agent clients that requested SSE (via tasks/sendSubscribe), the SSE connection acts as a consumer of the above events:
We implement an SSE stream handler that listens for events for that specific Task. One approach is that when a tasks/sendSubscribe call comes in, we immediately flush a “connected” SSE event and then subscribe to the Task’s events. In Laravel, we might not have an out-of-the-box event loop, but we can simulate it:
The SSE controller action can use a loop with Event::listen or use the event dispatcher to receive events. When TaskManager fires an event for that task ID, the SSE handler will catch it (perhaps using a minimal publish/subscribe system in memory or checking the Task state periodically). Because PHP scripts have a request scope, another strategy is to periodically poll the database for updates. However, that’s inefficient. A more responsive design is to leverage Laravel’s broadcasting as a signaling mechanism: the SSE action can listen on an internal queue (e.g., Redis pub/sub). For simplicity, we might leverage the fact that events are queued: the SSE handler could block-read from a queue channel for the task. This is complex to implement purely in PHP without async support, so as a first version, we may choose a simpler route: stream periodic updates.
Nonetheless, the plan is to wire SSE to the event system. For example, when TaskStatusUpdated is fired, we could write to a concurrent data store (like Redis) and the SSE loop polls that with low latency to fetch new events. The SSE response then writes the event data (in JSON) out to the client and flushes. We mark final events to break the loop.
Each SSE event data uses the JSON structure defined by A2A: a JSONRPCResponse with the original request id and a result containing either a TaskStatusUpdateEvent or TaskArtifactUpdateEvent
google.github.io
. We format our events accordingly. We do not close the connection until final: true or an error occurs, as per spec
google.github.io
. The Laravel app must be configured to allow these long-lived connections (we might disable its execution time limits or use something like Laravel Octane for better support).
The SSE mechanism is internal to the agent-to-agent communication. We do not require the developer to manage it; the package handles the low-level details. They simply need to enable streaming in config, and the package will advertise it and do the rest.
Push Notifications (Webhooks for Async Updates): If a calling agent set up a push webhook via tasks/pushNotification/set, our agent will deliver task updates to them without them polling or using SSE. Here’s how our package manages this:
When a push config is saved for a Task (via the RPC call), we store the target URL, token, and auth in the PushNotificationConfig model. We also mark the Task as having push subscribers.
We provide a PushNotificationListener (Laravel event listener) that listens to the Task events (especially TaskStatusUpdated and TaskCompleted/Failed). This listener checks if the task has a push config. If yes, it serializes the update into a webhook payload and enqueues an HTTP POST request to the client’s URL. The payload can be the full Task object or a slim event object. According to spec, we might send the entire Task on each significant update, or just the delta. A safe approach is to send the same JSON one would get via tasks/get at that moment
google.github.io
 (i.e., Task ID, state, message, maybe new artifacts). The listener uses Laravel’s queue to perform the HTTP call asynchronously. We utilize the configured auth info: e.g., if the client provided a token, add it as X-A2A-Notification-Token header as suggested
google.github.io
; if they provided auth credentials, use them (for example, basic auth or Bearer token). The Http client performs the POST to the absolute URL provided (ensuring it’s HTTPS as required
google.github.io
).
Retry and Error Handling: We implement retry logic for webhook deliveries (honoring typical webhook patterns). If a push POST fails (network error or 500), Laravel’s queue retry mechanism will attempt again a few times. We also might fire our own event like TaskPushDeliveryFailed if ultimately not reachable (so developers can log or handle it). This ensures reliable at-least-once delivery of updates.
Receiving Push (acting as client): Conversely, if our agent sets up push on a remote agent, we include in config a WebhookController to receive incoming task notifications. This is essentially handling the remote agent’s calls to us. By default, we can mount it at something like POST /a2a/push/{taskId} or a single endpoint that looks at the payload to find the task. It will verify the token (to ensure authenticity), then update our local Task record with the provided status or artifacts. It then fires our local Task events so our UI or logs update accordingly. This closes the loop, allowing our agent to seamlessly integrate results from others.
Laravel Echo / Broadcasting (UI Notifications): Although agent-to-agent uses SSE/webhooks, a developer integrating this package may want their own front-end to monitor tasks in real time (for example, an admin panel showing what tasks are running, or a user’s browser getting results of a task they initiated). We leverage Laravel’s broadcasting system for this purpose:
The Task events (TaskStatusUpdated, etc.) can implement ShouldBroadcast. We define broadcast channels, e.g., agent-tasks as a public or private channel for aggregate updates, and agent-task.{id} as a private channel for a specific task. The package can broadcast minimal info (task ID and new state) on the public channel for monitoring, and detailed info on the specific channel. Developers can use Laravel Echo in JavaScript to listen on those channels (e.g., Echo.channel('agent-task.{$id}').listen('TaskStatusUpdated', ...)) to update UI in real time.
We include events in the broadcast payload that mirror the JSON structure from SSE, so the front-end gets the same data. Alternatively, the front-end could call the REST tasks/get to retrieve fresh data when notified of a change.
The broadcasting is optional (requires the app to configure a broadcaster like Pusher or Redis). If not configured, it doesn’t affect core A2A functionality. But having it built-in means as soon as a developer sets up Echo, they get live task updates without further coding.
Event Handling Summary: All these mechanisms are triggered by the same internal events, ensuring consistency. For example, when a task completes, the sequence is: Task model updated -> TaskCompleted event fired -> (a) SSE stream sends update, (b) PushNotificationListener queues a webhook, (c) Broadcast (Echo) sends update to UI, (d) any custom user listeners also get the event. This unified approach makes the system extensible and debuggable, and follows Laravel idioms (model events / domain events drive downstream actions).
Skill Discovery and Extensibility
One of the package’s goals is to be easily extendable by developers adding their own skills or customizing behavior:
Skill Registration via Config: The simplest method: in the config/a2a.php file, developers can list their skill classes or define inline closures. For example:
php
Copy
Edit
'skills' => [
    \App\A2A\Skills\CurrencyConverter::class,
    \App\A2A\Skills\ImageGenerator::class,
    'text-summarizer' => [
        'name' => 'Text Summarizer',
        'description' => 'Summarizes a given text.',
        'handler' => function(Task $task, Message $input) {
            // ... summarize text ...
            return $summary;
        },
    ],
],
The package’s service provider will loop through this config. For each entry:
If it’s a class string, resolve the class (via the Laravel container or new instance) and ensure it implements the Skill interface. It will then call methods or properties to get id, name, etc., and register the instance in SkillRegistry. If the class doesn’t define an explicit ID, we could default to a slug of the name or class name.
If it’s an array with a 'handler' closure, we expect an 'name' and 'description' and optionally an explicit 'id'. If no id given, generate one (e.g., slug from name or an index). Then register a skill with those metadata and the closure as the execute function.
We allow both to encourage quick prototyping (closures) and structured design (classes).
Auto-Discovery of Skills: In addition to config, the package supports auto-discovery to reduce manual steps. We can scan the application (and any installed packages) for classes tagged with a special marker. Possible approaches:
Service Provider Binding: A developer could bind skills in a custom ServiceProvider (using our package’s API like SkillRegistry::register(new MySkill())). We will set extra in composer.json to enable Laravel package discovery so that any ServiceProvider in the skills directory (convention) is automatically loaded.
Class Scanning: Use PHP reflection to iterate over a namespace. We might specify in config something like 'skill_namespace' => 'App\\A2A\\Skills'. On package boot, we reflect on that namespace’s classes (which are autoloadable) to find those implementing SkillInterface. This is done carefully to avoid performance hit (maybe only in dev or behind a caching command). For production, we can have an artisan command to cache the skill manifest.
Attributes/Annotations: Optionally support PHP 8 attributes for skill classes, e.g., a #[A2ASkill(id: "foo", name: "...")] attribute on the class. We could detect those via reflection. This can make registration as simple as adding an attribute to a class and not touching config at all. This is more of a nice-to-have; the core will work with config and interface approach regardless.
Extending Task Processing: The package is built with Laravel’s extendability in mind. Key extension points:
Event Listeners: Developers can add listeners to the Task events to plug in custom logic (perhaps logging, or triggering other processes on completion). We document the events and their data contracts so users can safely consume them.
Replacing Services: All core services (AgentService, TaskManager, etc.) are bound in the container behind interfaces. If an app needs to override some logic, they can rebind, for example, A2A\Interfaces\TaskManagerInterface to a custom implementation in their AppServiceProvider. We use sensible defaults but don’t hard-code final classes where not necessary. For instance, one might swap out our HTTP client logic with a customized one (perhaps to integrate with a specific logging or retry policy) by binding a different A2AClient.
Skill Execution Customization: By default, skill methods run either synchronously or in our queued job. If a developer wants all skills to always run in queue (to not tie up web workers), they can configure that in a2a.php (e.g., 'default_async' => true). Conversely, they can mark individual skill classes with a property like $runSync = true to bypass queuing for trivial tasks. The TaskManager will respect those settings.
Multi-agent Orchestration: If building a complex orchestrator agent, the developer might add logic to dynamically decide which remote agent to delegate to. Our package doesn’t enforce how tasks map to skills; a skill could actually be an orchestrator that, when executed, uses the A2AClient to call another agent and returns that result. The framework supports this because the skill code can call AgentService::sendTaskToAgent internally. Essentially, it can create nested tasks. We’ll ensure re-entrant capabilities (the TaskManager can handle being invoked from within another task’s skill without deadlocking, etc.).
Configuration Hooks: The config file a2a.php also includes toggles for capabilities (enable/disable streaming, push) so that the Agent Card reflects what the developer wants. If for example their deployment environment can’t handle SSE, they might turn off 'streaming' => false – our agent card will then not advertise it (and the controller will reject any tasks/sendSubscribe calls with a proper error code
google.github.io
). Similarly, push can be disabled if not desired.
Testing and Mocks: For testing purposes (discussed more below), the package allows injecting fake skill behaviors. For instance, a developer can swap a real skill class with a dummy that returns a preset output, to test the task pipeline. The SkillRegistry might have methods to replace or unregister a skill at runtime for test scenarios.
Documentation and DX: We will provide clear PHPDoc on all interfaces and classes, making IDE auto-completion helpful. The package will also include a README or docs covering how to add new skills, how to configure auth, etc., to ensure developers can adopt it quickly without needing to deeply understand A2A spec details. Our implementation abstracts most of that, presenting a Laravel-idiomatic API (e.g. dispatching tasks, listening for events, writing simple skill classes) that feels familiar.
Artisan CLI Tools for A2A
To improve developer experience, the package introduces Artisan commands that streamline common tasks and debugging:
a2a:discover {url} – Discover an Agent: Given a base URL or domain of another agent, this command fetches the /.well-known/agent.json Agent Card. It will output the parsed details: agent name, description, listed skills, capabilities, etc. This helps developers quickly verify another agent’s capabilities and ensure connectivity. For example: php artisan a2a:discover https://weather.example.com would perform an HTTP GET to https://weather.example.com/.well-known/agent.json and then pretty-print the JSON or a summary. It will also handle any authentication if needed (perhaps prompt for a token if the agent card is protected). Under the hood, this uses the AgentService discovery function. This command can also cache the AgentCard in a local file or database table (like an “Agent” model) for later use by the app.
a2a:skill:list – List Local Skills: Outputs all skills registered in the local agent. This will show each skill’s ID, name, and description (and possibly tags or example usage). It’s useful to confirm that the skills have been registered correctly and are being advertised as expected. It pulls from the SkillRegistry, so any auto-discovered or config-registered skills should appear. Developers might use this to ensure their new skill class is recognized.
a2a:task:send {agentUrl} {skillId?} {--message=} – Send a Task to Remote Agent: Allows sending a one-off task to a specified remote agent for testing. The command takes the agent’s URL (or perhaps an alias if we maintain a list of known agents in config), an optional skill ID or just a message. For example: php artisan a2a:task:send https://weather.example.com "weather-forecast" --message="What's the weather tomorrow?". This will use the A2AClient to perform the JSON-RPC call to the remote agent. By default it might use tasks/send (synchronous). We could add flags like --stream to use tasks/sendSubscribe for streaming, or --push to register push (in which case our local agent needs to be running to catch the callback). The command will print out the results or stream updates to the console. For streaming, we can output each SSE event as it arrives (printing status updates live). This tool is invaluable for debugging integration with remote agents and ensuring our agent can communicate properly.
a2a:task:receive {taskId} – (Potential command) This could simulate receiving a task on the local agent (for testing a skill manually). For instance, php artisan a2a:task:receive test-skill --message="Test input" would internally invoke our own agent as if an external request came in. It’s essentially a shortcut to trigger a skill locally and see the output, going through the TaskManager. This is useful for testing skill logic without setting up an external call. (This command would basically call AgentService->handleSend with given params and output the Task result).
Command Implementation: All commands leverage the underlying services. They are registered in the package’s service provider under the Artisan commands. We ensure they provide helpful console output and accept arguments in a user-friendly way (with clear descriptions, argument types, etc.). For instance, a2a:discover will nicely format JSON using Symfony Console’s styling, and a2a:task:send will indicate progress (maybe “Task submitted… got response…”).
Use in Development: These tools make it easy to interact with the A2A system during development. A developer can spin up two Laravel apps with the package – one as a dummy agent – and use these commands to simulate interactions (e.g., from App A call a2a:task:send to App B and see the result, or use a2a:discover to fetch App B’s card). This complements automated testing by allowing manual exploration.
JSON-RPC Compliance and Validation
The package strictly follows JSON-RPC 2.0 format for all communications, making it interoperable with other implementations:
Request Validation: Incoming requests are validated against JSON-RPC 2.0 requirements and A2A-specific method schemas. We ensure "jsonrpc": "2.0" is present and correct, the id is present (for requests expecting a response), and the method is one of the supported ones. The params structure for each method (TaskSendParams, TaskQueryParams, etc.) is validated: for example, tasks/send must have a string id and a message object; tasks/cancel must have an id string, etc. We can use Laravel’s FormRequest or a custom validator for this. On validation failure, we return a well-formed JSONRPC error with code -32602 (Invalid params) or -32600 (Invalid request) as appropriate, per JSON-RPC spec
google.github.io
.
Response Formatting: All responses are JSON-serialized following JSON-RPC format. We take care to only include allowed fields. For example, a successful response will be: {"jsonrpc": "2.0", "id": "<same as request>", "result": { ... }} and no error. In case of errors, we return {"jsonrpc": "2.0", "id": "<same or null if not provided>", "error": { "code": <code>, "message": "<desc>", "data": <optional> }}. The error codes and messages follow A2A spec definitions where applicable (e.g., using PushNotificationNotSupportedError code if someone calls pushNotification/set but we advertise no support). We will define a set of exceptions or error classes to map to these codes, making error handling consistent.
Clean JSON Serialization: We avoid exposing internal Eloquent attributes in API responses. We will likely use dedicated DTOs or array transformers for AgentCard, Task, Message, etc., rather than directly serializing Eloquent models. For instance, the Task model’s toArray() might be customized via toArray() override or using Laravel API resources to format fields exactly as the spec expects (id, status, history, artifacts, etc.). We ensure fields like internal IDs or foreign keys that are not part of the spec are excluded. Only the meaningful data is output. This way, the JSON that other agents see is clean and spec-compliant.
For AgentCard: we assemble an associative array or resource that has keys name, description, url, version, capabilities, authentication, skills, ... as defined. We ensure types match (e.g., capabilities.streaming is boolean, not 1/0).
For Task: we output id, sessionId, status, artifacts, history, metadata per the interface
google.github.io
google.github.io
. The status itself is an object with state, message, timestamp. If message exists, it’s a Message object (with role and parts). History is an array of Message objects (if requested). Artifacts is an array of artifact descriptors (with fields like name, parts, etc.). We will likely create Laravel API Resource classes for Task, Message, Artifact to handle this conversion systematically.
JSON-RPC Batch Requests: The spec primarily discusses single requests, but JSON-RPC 2.0 allows batching. Our controller could handle an array of request objects in one payload. This is a nice-to-have: we can detect if the incoming JSON is an array and if so, process each entry and return an array of responses. This isn’t heavily emphasized for A2A, but supporting it can enhance interoperability.
Testing Compliance: We will use the spec’s examples to test our serialization. For example, if the spec’s sample workflow shows a certain JSON structure for a Task response
google.github.io
google.github.io
, we’ll ensure our output matches that structure exactly (field names, nesting). This gives confidence that any client following the spec can consume our agent’s output without issues.
Versioning: The Agent Card includes an Agent.version (which we populate from config) to indicate our agent or package version. If the A2A protocol version ever updates (0.1.0 currently
google.github.io
), we can bump our package and reflect any breaking changes. We might also include the protocol version in the AgentCard (possibly in metadata or part of version string).
Security Considerations: Although not directly about JSON formatting, being spec-compliant also means handling security-related fields. For example, if an Authentication scheme requires certain response headers or challenge (not covered in the spec deeply), we remain flexible. If our agent uses OAuth, we might need to implement an OAuth flow outside A2A (obtaining tokens). The package leaves such authentication flows to the developer but ensures that the presence of auth requirements is known (via the AgentCard) so clients can prepare accordingly.
Testing Support and Pest Integration
The package is designed to be thoroughly testable, and we provide tools to simulate multi-agent interactions using Pest (or PHPUnit):
Pest Test Suite: We include a test suite (written in Pest for a fluent, BDD-like style) within the package to verify all features. These tests will also serve as examples for users. For instance, we’ll have tests for:
Agent Card generation: ensuring the .well-known/agent.json route returns correct JSON matching the config and including all registered skills.
Task lifecycle: creating a dummy skill that, say, echoes the input after a delay. Then simulate a tasks/send request (perhaps by calling the Laravel HTTP client within the test or directly invoking the controller) and asserting that the Task goes from submitted -> working -> completed, and that the final response contains the expected output.
State transitions: tests where the skill deliberately triggers an input-required state (throwing InputRequiredException) and verifying that the agent responds with state input-required and that subsequent tasks/send with more input leads to completion.
Push and SSE flows: using Pest, we can simulate push by providing a dummy webhook endpoint. For example, we might start a small HTTP server in a separate thread to receive webhooks, or more practically, we mock the HTTP client used for push calls to capture the payload. Then we assert that on task updates, the push payload matches the expected Task data. SSE is harder to fully simulate in a test environment, but we can test the controller logic that sets up SSE by invoking it and then, for example, dispatching events and seeing if the response stream (maybe captured by an OutputBuffer) contains the correct event data. Alternatively, we might factor out an SSE emitter class and unit test it by feeding it events.
Concurrent agent interaction: We can simulate two agents by instantiating two sets of routes within the test (perhaps using Laravel’s Http client to call between them). For instance, spin up a Laravel application instance configured as Agent A and another as Agent B. Agent B will have a sample skill (like “EchoSkill” that returns whatever input). In the test, we call Agent A’s method that uses the A2AClient to send a task to Agent B. We then assert that Agent B processed it and Agent A received the result. This could be done without actual HTTP by calling directly through our service classes with mocked network, or by making real HTTP calls to the Laravel app in testing mode (Laravel’s testing can call routes on itself, and we could potentially call between two apps by pointing to a testing URL if using something like Symfony Http kernel bridge). If running two processes is complex, an easier approach is to have Agent B’s logic be invoked via a fake client callback. We might abstract the HTTP layer so in tests we replace A2AClient with a stub that calls a local function representing Agent B. That stub would utilize AgentService of Agent B to produce a response. Thus, we can simulate the round-trip without network.
Factories and Seeders: We provide model factories for Task, Message, and Artifact to facilitate testing. A developer writing tests in their own app can use Task::factory()->create([...]) to quickly set up a task in a given state with related messages/artifacts. This helps in testing their own skill logic or how their app reacts to task events. For example, one could factory-create a Task in state "completed" with some artifacts, then call their controller that lists tasks and assert the JSON structure.
Test Doubles for Skills: We allow easy injection of fake skills during testing. For instance, the package might have a trait InteractsWithA2A that provides methods to register a fake skill on the fly. A test can do something like:
php
Copy
Edit
$this->registerTestSkill('test-skill', function($task, $message) {
    return "Hello ".$message->content;
});
Then simulate a tasks/send call for 'test-skill' and assert the response. This prevents needing to create actual skill classes for simple test cases.
Multi-Agent Scenario Testing: We will document how to test scenarios where one Laravel application (or one instance of the package) interacts with another. If an end developer has two apps, they can use our testing utilities to stub out one side. For instance, we might provide an in-memory fake agent server that implements the A2A spec (like a FakeAgent class that can mimic responses for certain skills). The user could configure the A2AClient in test to use the FakeAgent instead of real HTTP. This way, when they call their service to delegate a task, the FakeAgent returns a predetermined result, and they can assert that their handling of that result is correct.
Pest Plugins: If needed, we could offer a Pest plugin or helper functions for common assertions, e.g., expectTask($task)->toHaveState('completed') or expectPushDelivered($taskId)->to($url) etc., to make tests more expressive.
Continuous Integration: Our own package tests (which will likely use Pest) act as a reference to ensure all components work together. We will include tests for edge cases (like receiving an unknown task ID, ensuring it returns a TaskState "unknown" error, or testing that the Agent Card JSON is valid).
Example Tests: The package documentation might include a sample Pest test that starts a mini agent and sends it a task. This can double as a tutorial for users to run and modify. Because the user specifically mentioned Pest, we assume familiarity, and we’ll leverage Pest’s readability to make tests serve as documentation.
By providing robust testing support, we ensure that developers can trust the package in critical workflows and also can build on it (or modify it) without fear of breaking core A2A functionality – tests will catch any regressions. Ultimately, the package aims to deliver a Laravel-native experience for A2A: Eloquent models, events, queues, and artisan tools all integrated so developers can adopt the Agent-to-Agent protocol with minimal friction, focusing on writing their skills and application logic rather than the protocol plumbing
medium.com
medium.com
. With this implementation plan, the Laravel package will facilitate easy discovery of agents, management of task lifecycles, real-time updates via SSE/push, and an extensible architecture for future growth, all while conforming to the A2A specification’s requirements. Sources: The Agent-to-Agent protocol specification was referenced for required features and data structures
google.github.io
google.github.io
, ensuring our design aligns with the standard.



